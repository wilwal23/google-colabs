{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyZv2P96PGqqA91jzqdpJf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wilwal23/google-colabs/blob/main/simple_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "YMS7DFK5hg5X"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "training_data.data = training_data.data.view(-1, 784).float()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming you have training_data and test_data\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True, pin_memory=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "t97IBBZLvD41"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_yqj1TC-vTpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # Call the constructor of the parent class (nn.Module)\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Define the first fully connected layer\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        # Define the second fully connected layer\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through the first fully connected layer\n",
        "        x = torch.relu(self.fc1(x))\n",
        "\n",
        "        # Pass the output through the second fully connected layer with tanh activation\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "\n",
        "        # Return the final output\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # Call the constructor of the parent class (nn.Module)\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Define the first fully connected layer\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        # Define the second fully connected layer\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through the first fully connected layer with ReLU activation\n",
        "        x = torch.relu(self.fc1(x))\n",
        "\n",
        "        # Pass the output through the second fully connected layer with sigmoid activation\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "\n",
        "        # Return the final output\n",
        "        return x"
      ],
      "metadata": {
        "id": "0E2SDIbQhkSx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU if available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set the input and output sizes for the generator and discriminator\n",
        "input_size = 784  # Assuming input size for both generator and discriminator is the same\n",
        "hidden_size = 256\n",
        "output_size = 1\n",
        "\n",
        "# Create instances of the Discriminator and Generator, and move them to the specified device\n",
        "discriminator = Discriminator(input_size, hidden_size, output_size).to(device)\n",
        "generator = Generator(input_size, hidden_size, output_size).to(device)\n",
        "\n",
        "# Set the loss function (Binary Cross Entropy with Logits) for training the discriminator\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Set the optimizers for the discriminator and generator\n",
        "\n",
        "# Adam optimizer for the discriminator\n",
        "# Parameters: discriminator.parameters() - All parameters of the discriminator\n",
        "# Learning rate: lr=0.0002 - Rate at which the optimizer adjusts the model weights\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "\n",
        "# Adam optimizer for the generator\n",
        "# Parameters: generator.parameters() - All parameters of the generator\n",
        "# Learning rate: lr=0.0002 - Rate at which the optimizer adjusts the model weights\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002)"
      ],
      "metadata": {
        "id": "qDn_qcftiTMO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of training epochs and the size of the noise vector used as input to the generator\n",
        "num_epochs = 200\n",
        "noise_size = 784\n",
        "\n",
        "print(train_dataloader.dataset.data.size())\n",
        "print(train_dataloader.batch_size)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "noise = torch.randn(batch_size, noise_size).to(device)\n",
        "\n",
        "reshaped_tensor = noise[0].view(28, 28)\n",
        "\n",
        "# Convert tensors to numpy arrays\n",
        "flattened_array = noise[0].numpy()\n",
        "reshaped_array = reshaped_tensor.numpy()\n",
        "\n",
        "# Plot the original and reshaped tensors\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(reshaped_array, cmap='gray')\n",
        "plt.title('Reshaped (28x28)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3e5gFSqMEkcu",
        "outputId": "659dde7e-5047-4003-edc6-f73891e8f9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 784])\n",
            "64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS0AAAFECAYAAAByGGh8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfZUlEQVR4nO3deViVdd7H8e+BOBwOIMgqI4iJIimSiOGOQ+aSElGjM5WmpraoYzZdpTVWBuqY1ihThJMbjZWa21R2VS65lHMpjvtSKuKCiaCAJooiy/f5o4czncD4MI+O83v6vK7LP+b05tznIH7nBn7377aoqgoRkSFcbvULICJqCA4tIjIKhxYRGYVDi4iMwqFFREbh0CIio3BoEZFROLSIyCgcWkRkFA4tQwwfPly8vLxu9cv4t2zatEksFots2rQJ6mfOnClRUVFSXV19c1/YLVJRUSFhYWGSmZl5q1+KkTi0Gujdd98Vi8Xi+HPbbbdJ06ZNZfjw4XL69Olb/fKMd/HiRZkxY4ZMnDhRXFx++PIsLi6W119/XRISEiQwMFB8fX2lc+fO8uGHH9b5HDk5OfLQQw9JaGio2O12iYqKkrS0NCkrK2vw67kZx3Zzc5Nnn31Wpk2bJlevXm3wa/rFU2qQrKwsFRFNS0vT9957T+fNm6cjR45UV1dXjYiI0CtXrtyU4w4bNkw9PT1vynPfbBs3blQR0Y0bN9bbzp49Wxs1auT0eVy9erW6ubnp/fffr+np6ZqRkaGJiYkqIvrKK684fXxeXp76+vpqeHi4Tp8+Xd955x0dPny4iogmJyc3+LXfrGOfP39erVarLliwoMGv6ZeOQ6uBaobWP//5T6fHJ06cqCKiH3744U057i9laMXExOiQIUOcHjt27JieOHHC6bHq6mq9++671d3dXS9duuR4fNq0aSoieuDAAad+6NChKiJaUlLSoNd+M4+dlJSkPXr0aNDrIVV+e3iD9OjRQ0REcnNznR4/dOiQDBw4UPz8/MRms0nHjh3lk08+cWoqKiokNTVVWrVqJTabTfz9/aV79+6ybt26Wsc5ffq0pKSkiJeXlwQGBspzzz0nVVVVTs0bb7whXbt2FX9/f/Hw8JC4uDhZsWJFreeyWCzy+9//Xj744ANp3bq12Gw2iYuLk6+++qrO444YMUKCg4PF3d1d2rZtKwsXLqzVfffdd5KSkiKenp4SFBQkf/jDH6S8vLz+T6CIHD9+XPbt2yf33HOP0+O33367hIeH13rtKSkpUl5eLseOHXM8fvHiRRERCQ4OdupDQkLExcVFrFariIhkZWWJxWKp9R7+9Kc/icVikc8+++ymHbtG7969ZcuWLVJSUvIznxWq5VZPTdNc70wrIyNDRUTnzJnjeOzAgQPq4+Ojbdq00RkzZmhGRoYmJCSoxWLRVatWObo//vGParFY9PHHH9d58+bpn//8Z3344Yf1tddeczTDhg1Tm82mbdu21REjRuicOXP0N7/5jYqIZmZmOr2W0NBQHTNmjGZkZOisWbM0Pj5eRUQ//fRTp05ENDo6WgMCAjQtLU1nzJih4eHh6uHhofv373d0BQUFGhoaqmFhYZqWlqZz5szR5ORkFRGdPXu2oysrK9PIyEi12Ww6YcIETU9P17i4OI2JiYHOtN5//30VEd23b1+9fw81nzcR0fz8fMdjn3/+uePbsd27d2teXp4uXbpUGzVqpM8884zTxyclJamPj4/m5eWpquq+ffvUarXqyJEjb/qxVVW3bNmiIqKrV6+G3i/9gEOrgWqG1vr16/XcuXN66tQpXbFihQYGBqq7u7ueOnXK0fbq1UvbtWunV69edTxWXV2tXbt21VatWjkeu/POO3XAgAE/e9xhw4Y5fpb2Y7GxsRoXF+f0WFlZmdP/vnbtmkZHR+vdd9/t9LiIqIjojh07HI+dPHlSbTabPvDAA47HRo4cqSEhIVpUVOT08Q899JD6+Pg4jpeenq4iosuWLXM0ly9f1pYtW0JD66WXXlIR0dLS0p/tVFWLi4s1KCiozm+vpkyZoh4eHo73JyI6adKkWt2ZM2fUz89Pe/fureXl5RobG6vNmjXT77///qYfW1U1Pz9fRURnzJhR7/ulf+HQaqCaofXTP82bN9c1a9Y4uuLiYrVYLDplyhQ9d+6c05/U1FQVEf3uu+9UVbVnz57avHlzPXLkyHWPWzO0zp496/T4008/rY0bN77ux5WUlOi5c+d09OjR6uvr6/TfRES7dOlS62N+97vfqd1u18rKSq2urlZfX1994oknar2Pms/Fli1bVFW1T58+GhISotXV1U7PN3PmTGhojR49Wm+77bafbVRVq6qqtF+/fmq1WnXPnj21/vt7772nffv21blz5+rKlSt1xIgRarFY9K233qrVLlmyREVE4+Pj1WKx6Pr16/9jx75y5YqKiD7//PP1vmf6Fw6tBqr5h/r222/runXrdMWKFdq/f3/18vLSTZs2Obrs7Ow6h9uP/+zatUtVVTdv3qy+vr6Ob9eee+453bt3r9Nxa749/KnJkyfrT7/LX716tXbq1End3d2djmexWJw6EdGhQ4fWes6XX35ZRUTPnDmjhYWF9b6Pmm91W7duXefZx8cff3xDh9aYMWNURHTRokW1/tuSJUvUw8PD6YxXVXX48OFqt9trnS2qqg4YMEBFRJ944on/6LHLyspURHTChAn1Hpf+5bb/20/Efrni4+OlY8eOIiKSkpIi3bt3l0ceeUQOHz4sXl5ejoWRzz33nPTt27fO52jZsqWIiCQkJEhubq58/PHHsnbtWpk/f77Mnj1b/vrXv8qoUaMcvaura72v6+uvv5bk5GRJSEiQzMxMCQkJETc3N8nKypLFixc3+H3WvI8hQ4bIsGHD6mxiYmIa/Lx18ff3l8rKSiktLRVvb+86m9TUVMnMzJTXXntNHn300Vr/PTMzU2JjYyU0NNTp8eTkZHn33Xdl9+7dTj/oLy4ulh07doiIyDfffCPV1dWO9WE3+9jnz58XEZGAgIA6j0d149C6AVxdXWX69OmSmJgoGRkZ8sILL0iLFi1E5IeFhD/9bVhd/Pz85LHHHpPHHntMLl26JAkJCfLqq686DS3EypUrxWazyZo1a8Td3d3xeFZWVp19Tk5OrceOHDkidrtdAgMDRUTE29tbqqqq6n0f4eHhcuDAAVFVsVgsjscPHz4MvfaoqCgR+eG3iHUNwrffflteffVVeeaZZ2TixIl1PkdhYaE0bty41uMVFRUiIlJZWen0+NixY6W0tFSmT58uL774oqSnp8uzzz77Hzn28ePHRUTkjjvuqPP56Dpu9ameaa7320NV1fj4eA0ODnYsjPz1r3+tfn5+Tr9hqvHjn03V9S3LoEGDNCAgwPG/r7dO66ffHj777LNqt9v18uXLjseOHz+udru91reR8r/f3u3cudPxWF5entpsNk1JSXE8Nnz4cLVarU6/UazrffxffxCfm5urIlLngsulS5eqi4uLDh48uNbPzH4sKSlJrVarHj582OnxlJQUdXFx0dOnTzseW758uYqIvvnmm6r6wy8WPDw8an3szTi2qupf/vIXtVgsdf790/VxaDXQzw2tmn8ENcseDh48qI0bN1Z/f3994YUXdO7cuTplyhTt37+/xsTEOD4uKChIf/vb3+qMGTN03rx5+uSTT6rFYtFx48Y5GnRoffnllyoi2qNHD50zZ46mpqZqUFCQY9nBj8l1ljzYbDann6kVFBRoeHi42u12HT9+vL7zzjs6ffp0HTRokNMvAWoGlM1m04kTJzZ4yYOqanR0tD788MNOj2VnZ6vVatXAwEBduHChvvfee05/cnNzHe3mzZvV1dVVg4KCNC0tTd9++2299957VUR01KhRjq6wsFADAgI0MTHRMYiKioo0ODhYu3TpolVVVTft2DWSkpK0e/fu9X5OyBmHVgP93NCqqqrSiIgIjYiI0MrKSlX94exh6NCh2qRJE3Vzc9OmTZtqUlKSrlixwvFxU6dO1fj4ePX19VUPDw+NiorSadOm6bVr1xwNOrRUVRcsWKCtWrVSd3d3jYqK0qysrDo7EdGxY8fq+++/7+hjY2PrHC6FhYU6duxYDQsLUzc3N23SpIn26tVL586d69SdPHlSk5OT1W63a0BAgI4fP16/+OILeGjNmjVLvby8nJZtXO83tjV/srKynJ4jOztb7733XsfnPDIyUqdNm6YVFRWO5sEHH1Rvb+9aq91rfmlQswzhZhxbVfXChQtqtVp1/vz59X5OyJlFlfc9/KWyWCwyduxYycjIuNUvxeH777+XFi1ayMyZM2XkyJG3+uXcNOnp6TJz5kzJzc0VDw+PW/1yjMLLeOi/io+Pj0yYMEFef/31/9db08yaNUteeuklDqx/A8+0fsH+G8+0iOrDMy0iMgrXaf2C8SSbTMQzLSIyCocWERmFQ4uIjAL/TKuua6rq8uKLL2IHvg07dF5eHtShF52iF/f++Lq9n/PTnUpvhLp2Dq0Les3a9S4A/in0GsEDBw5AXWpqKtRt3rwZ6q5cuQJ1NRey12fq1KlQN336dKhDv1bRnVxFRLZv3w517du3h7pvv/0W6mquO60PuiwF/btbtGhRvQ3PtIjIKBxaRGQUDi0iMgqHFhEZhUOLiIzCoUVERuHQIiKjcGgRkVE4tIjIKPB+WqNHj4aeEN3UrKCgAOrQ1dy333471P30jijXg64IdnNzgzoRkc8//xzqau7kU5/S0lKoQ3dz6NOnD9RdunQJ6tCV39u2bYO6mTNnQt2MGTOgLjY2Fuqudzuzn9qyZQvU2e12qBMRyc/Phzr0a6Fbt25Q9/HHH0Odn58f1HXu3BnqkCtqeKZFREbh0CIio3BoEZFROLSIyCgcWkRkFA4tIjIKhxYRGYVDi4iMwqFFREaBV8S/8sor0BOiK8StVivUoXu/7927F+qCgoKgDl3Z/+WXX0KdiMjjjz8OdTabDepWr14NdejVAugKdl9fX6ibNm0a1C1duhTq0CsKQkJCoA7dt/zMmTNQV1VVBXVffPEF1IngVwGsWbMG6tA95+Pj46EuMjIS6tavXw91yN8xz7SIyCgcWkRkFA4tIjIKhxYRGYVDi4iMwqFFREbh0CIio3BoEZFROLSIyCi3oSG6tzq6Ir6kpATq0JW0ERERUIfub46u0kb3VRfBV7rPmzcP6tq3bw916B7xJ0+ehDpPT0+o69evH9StWrUK6tCV/ej+5pMmTYK648ePQx269zu6n7uISG5uLtShV5g8+uijUIfem6GiogLqunbtCnUInmkRkVE4tIjIKBxaRGQUDi0iMgqHFhEZhUOLiIzCoUVERuHQIiKjcGgRkVHgFfF+fn5Qt2HDBqiLioqCujvuuAPq0BW3ZWVlUIfukX3vvfdCnQi+ejghIQHqvLy8oO7gwYNQt2nTJqjLycmBOvS+AgUFBVB34cIFqGvVqhXUoe8DvaKgWbNmUBceHg51IvjK9KZNm0Ld0aNHoQ7d7z4sLAzq0KsZEDzTIiKjcGgRkVE4tIjIKBxaRGQUDi0iMgqHFhEZhUOLiIzCoUVERuHQIiKjWBRc7ovuW47av38/1AUFBUGdq6sr1B0+fBjq4uLioG7dunVQJyLSpk0bqFu4cCHU3X///VAXHR0NddnZ2VCHXh2BroLetm0b1AUHB0Ndr169oG737t1Q16VLF6j7+uuvoS4vLw/qRPCv/3/84x9Q16hRI6hDXyP6fOjXYFZWVr0Nz7SIyCgcWkRkFA4tIjIKhxYRGYVDi4iMwqFFREbh0CIio3BoEZFROLSIyCjwHvGFhYVQ99FHH0FdUVER1KGrvvPz86EO3WccXTmPvg8RkQ4dOkAdurf6zp07oa68vBzqHnnkEajz8fGBusmTJ0MdeqVAYGAg1KH7qh84cADqTpw4AXXoPQDQ/dxFRHbt2gV16NcW2i1evBjqLBYL1PXu3RvqEDzTIiKjcGgRkVE4tIjIKBxaRGQUDi0iMgqHFhEZhUOLiIzCoUVERuHQIiKjwCviPT09oa5du3ZQl5CQAHX79u2DutDQUKgLCAiAuurqaqhD329DHD16FOo8PDyg7vz581C3atUqqENXsHft2hXq7rvvPqg7e/Ys1H3zzTdQV1VVBXV33XUX1KGrw9EV9iL4vvjo/vTo10JiYiLUoVeYHDp0COoQPNMiIqNwaBGRUTi0iMgoHFpEZBQOLSIyCocWERmFQ4uIjMKhRURG4dAiIqNwaBGRUeDLePbv3w91ISEhUDd//nyomzp1KtS9/PLLUPf8889DHfp+S0pKoE4EvyHEyZMnoa5JkyZQ5+rqCnU9e/aEOvRSEPRSqEmTJkEdeskUerMR9O8DvQFGbm4u1PXp0wfqRETKysqgrkePHlDXr18/qMvJyYG6vLw8qPP29oY6BM+0iMgoHFpEZBQOLSIyCocWERmFQ4uIjMKhRURG4dAiIqNwaBGRUTi0iMgo8Ir4wYMHQ93atWuhrlOnTlCH3hxh3LhxUHfw4EGoQzfsT05OhjoR/CqAyspKqLv77ruhrlGjRlC3YMECqENvbIFeVfDMM89AnZubG9Rt27YN6goKCqAOvYFIy5Ytoa64uBjqRETCwsKgDv13161bN6j77LPPoC4yMhLq0JuDIHimRURG4dAiIqNwaBGRUTi0iMgoHFpEZBQOLSIyCocWERmFQ4uIjMKhRURGsaiqIuHkyZOhJ0T3lr569SrUoaugLRYL1MXHx0Mdug86uv+6iIi/vz/UoXuSR0dHQ9327duhLiEhAeqOHj0KdejrQ/fEP3LkCNRZrVaou/POO6EuOzsb6k6fPg11Xbp0gToRkTNnzkBds2bNoG7Xrl1QFxoaCnXofQrQr+nly5fX2/BMi4iMwqFFREbh0CIio3BoEZFROLSIyCgcWkRkFA4tIjIKhxYRGYVDi4iMAu8R37ZtW6iLjY2FuoqKCqhD9xn/9ttvoW7Dhg1Ql5qaCnVpaWlQJyLy5JNPQh264hxd6d64cWOoQ68CQK9mKCoqgrq4uDio8/T0hLqqqiqoW7NmDdTFxMTc0OMGBwdDnQh+v4CysjKos9vtUIfud4/+u0PnAoJnWkRkFA4tIjIKhxYRGYVDi4iMwqFFREbh0CIio3BoEZFROLSIyCgcWkRkFHhF/Nq1a6GuvLwc6q5duwZ13bt3hzp0RTC6p/vf/vY3qPvkk0+gTgRfmX7PPfdAHbqCfdmyZVDXvHlzqEP/jtGV87Nnz4Y6dOV8QUEB1HXu3Bnq8vPzoa5du3ZQt3XrVqgTEQkPD4c6dI/4Nm3aQN2hQ4egLiIiAup27twJdQieaRGRUTi0iMgoHFpEZBQOLSIyCocWERmFQ4uIjMKhRURG4dAiIqNwaBGRUeAV8R07doQ6q9UKdevXr4e6Xbt2QR26SjswMBDq0D2yBw4cCHUiIh06dIC67OxsqPv++++h7sKFC1BXUlICdehqafQKgL59+0IdCt23/KGHHoI69OqIvLw8qLt48SLUiYgUFxdD3aZNm6CuS5cuUOfh4QF16NcCenUEgmdaRGQUDi0iMgqHFhEZhUOLiIzCoUVERuHQIiKjcGgRkVE4tIjIKBxaRGQUeEU8uorXbrdD3blz56Bu9OjRUIeuuF23bh3Uubhg8/zAgQNQJyISExMDdeiq/f3790PdhAkToG7z5s1QN2zYMKjbvn071Pn7+0Mduvf70KFDoW7hwoVQd/ToUaizWCxQFxwcDHUi+FUPI0aMgLqQkBCoO3v2LNR9/fXXUNe2bVuoQ/BMi4iMwqFFREbh0CIio3BoEZFROLSIyCgcWkRkFA4tIjIKhxYRGYVDi4iMAq+ILy0thbqtW7dCXadOnaCuqKgI6j755BOoi4uLg7pTp05B3VNPPQV1DTl2amoq1LVp0wbqjh8/DnXofuR33nkn1KEr9vPz86GurKwM6mbNmgV1vXr1gjr089y+fXuo++CDD6BORCQpKQnqli5dCnUvvPAC1J04cQLqPD09oc5ms0EdgmdaRGQUDi0iMgqHFhEZhUOLiIzCoUVERuHQIiKjcGgRkVE4tIjIKBxaRGQUi6oqEkZHR0NPOHXqVKi7cOEC1KH7jIeHh0Odt7c31DVk73cUuuK8RYsWULdjxw6oQ1c3t2vXDuo6duwIdehVFOiq6i+//BLq0D3nmzVrBnXo5+/BBx+EuoZA92AfNGgQ1KHvBd3Tfffu3VBXUVEBdePHj6+34ZkWERmFQ4uIjMKhRURG4dAiIqNwaBGRUTi0iMgoHFpEZBQOLSIyCocWERkF3iN+woQJUIfu952TkwN1t99+O9Sh+6+np6dD3dChQ6EO3cNeROSrr76CukaNGkEduuL8vvvug7rExESoW7JkCdSNGTMG6tCV/Rs2bIA6dBV5YWEh1J0/fx7qQkJCoO7SpUtQJyLi4+MDdXv37oW6nTt3Qt2ePXug7vDhw1DXrVs3qEPwTIuIjMKhRURG4dAiIqNwaBGRUTi0iMgoHFpEZBQOLSIyCocWERmFQ4uIjALvEf/aa69BT3j58mWoCw4Ohjp0L/nQ0FCo27p1K9S1b98e6vLy8qBOROSuu+6Cul27dkEdulr622+/hbrJkydD3cqVK6HOy8sL6tC9893c3KDu0KFDUHf16lWo69y5M9QdO3YM6qxWK9SJiHh4eEAd+M9YysvLoQ690qNfv35Qh35tIfdm4JkWERmFQ4uIjMKhRURG4dAiIqNwaBGRUTi0iMgoHFpEZBQOLSIyCocWERkF3iMeXfmNrmB3dXWFutzcXKhDV1+npKRAHfo+0D3sRUSmTZsGdS+//DLU+fv7Q93u3buhbvDgwVCH7jmPvj50xX5kZCTUoSvOKyoqoA6FrkoPDAyEnxNZIS4iEhYWdkOfD71648knn4Q69IoaBM+0iMgoHFpEZBQOLSIyCocWERmFQ4uIjMKhRURG4dAiIqNwaBGRUTi0iMgo8Ir4hIQEqIuNjYU6dJU2utJ3y5YtUFdSUgJ1ZWVlUBcSEgJ1IiKLFi2CuszMTKhDV5x37doV6kaNGgV1EyZMgLqhQ4dCXe/evaHu6NGjUOfigv1/MXo/gxUrVkDdwIEDoQ7d910EvzLjwQcfhLrz589D3YABA6AO/VwXFBRAHXTMG/ZMRET/ARxaRGQUDi0iMgqHFhEZhUOLiIzCoUVERuHQIiKjcGgRkVE4tIjIKBYFN7bOysqCnnDv3r1Qd+nSJaiz2+1Qh64y7tatG9QdOnQI6tD9zUVE2rVrB3Xbtm2DuqSkJKj7/PPPoc5isUAduld7ZWUl1JWWlkIderXF1q1boS4nJwfqvL29oQ5dHX7ixAmoExF55JFHoA69WgDdF9/T0xPqgoODoe7s2bNQ9+abb9bb8EyLiIzCoUVERuHQIiKjcGgRkVE4tIjIKBxaRGQUDi0iMgqHFhEZhUOLiIzCoUVERoFvbIHeBKB169ZQt337dqhDL/dp0qQJ1M2ZMwfqmjdvDnVt27aFOhH8JgV+fn5Qh14mExcXB3VXr16Fuu++++6GPl/79u2hDr15SXV1NdShN4NYvnw51CUmJkId+vpERMrLy6Guc+fOUPfRRx9BnZubG9RFRUVB3Y3EMy0iMgqHFhEZhUOLiIzCoUVERuHQIiKjcGgRkVE4tIjIKBxaRGQUDi0iMgp8Y4unnnoKekJ0o/uWLVtCXadOnaBu5cqVUHf69Gmo69evH9QtXrwY6kREAgMDoW7YsGFQt3HjRqhDb77Rs2fPG/p8165dg7r8/Hyo+9WvfgV1/v7+UIfeaOSbb76BuoKCAqhDv6ZFRNasWQN16FUFPj4+UIfe9MNqtUId+nc3atSoehueaRGRUTi0iMgoHFpEZBQOLSIyCocWERmFQ4uIjMKhRURG4dAiIqNwaBGRUeA94s+ePQt16F7tJ06cgLqKigqoO378ONRFRkZC3YYNG6CurKwM6kTwVcEvvfQS1KWmpkIdukL8zJkzUBcQEAB1+/btgzpvb2+oe+ONN6Du1KlTUId+/tD7FKB7+587dw7qRPB7LqB7uu/fvx/q0H+fgwYNgrojR45AHYJnWkRkFA4tIjIKhxYRGYVDi4iMwqFFREbh0CIio3BoEZFROLSIyCgcWkRkFHiP+HHjxkFPWFxcDHVXr16Fuh07dkDd6NGjoQ5djRwTEwN1f//736FOROTixYtQ17FjR6jLzc2Fuv79+0Pdrl27oO7TTz+FunvuuQfqOnToAHVeXl5Qt2zZMqhDV5ujr+/gwYNQh34diOAr3dGrGaKjo6EOfY2enp5Qd9ddd0FdUlJSvQ3PtIjIKBxaRGQUDi0iMgqHFhEZhUOLiIzCoUVERuHQIiKjcGgRkVE4tIjIKPAe8YWFhVDXokULqENX3LZs2RLqTp48CXXo6uaNGzdC3ZgxY6BOROStt96CugceeADqpkyZAnVr166FujvuuAPqIiIioG7IkCFQt3TpUqiz2WxQFxgYCHU5OTlQ9+ijj0Jd06ZNoQ79OhAROXbsGNRFRUVBnd1uhzp0pbu7uzvUofdwQPBMi4iMwqFFREbh0CIio3BoEZFROLSIyCgcWkRkFA4tIjIKhxYRGYVDi4iMAu8R//TTT0NP6OHhAXWlpaVQl5+fD3VBQUFQFxwcDHUBAQFQh+6rLoLvk42u7q+srLyhx718+TLUVVRUQF12djbUJScnQ92ePXugDt1LHr3KIzY2FuqKioqgzsUFP1dA97FHr3pArypYsmQJ1KFXbxQUFEDd4sWL6214pkVERuHQIiKjcGgRkVE4tIjIKBxaRGQUDi0iMgqHFhEZhUOLiIzCoUVERoFXxBMR/TfgmRYRGYVDi4iMwqFFREbh0CIio3BoEZFROLSIyCgcWkRkFA4tIjIKhxYRGeV/ANjEnTlyRHr6AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of training epochs and the size of the noise vector used as input to the generator\n",
        "num_epochs = 200\n",
        "noise_size = 784\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Iterate over batches in the dataloader\n",
        "    for i, (real_images, _) in enumerate(train_dataloader):\n",
        "        # Get the batch size\n",
        "        batch_size = real_images.size(0)\n",
        "        # Generate fake images\n",
        "        noise = torch.randn(batch_size, noise_size).to(device)\n",
        "        fake_images = generator(noise)\n",
        "\n",
        "        # Train the discriminator on real and fake images\n",
        "        d_real = discriminator(real_images)\n",
        "        d_fake = discriminator(fake_images)\n",
        "\n",
        "        # Calculate the loss\n",
        "        real_loss = loss_fn(d_real, torch.ones_like(d_real))\n",
        "        fake_loss = loss_fn(d_fake, torch.zeros_like(d_fake))\n",
        "        d_loss = real_loss + fake_loss\n",
        "\n",
        "        # Backpropagate and optimize\n",
        "        d_optimizer.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Train the generator\n",
        "        d_fake = discriminator(fake_images)\n",
        "        g_loss = loss_fn(d_fake, torch.ones_like(d_fake))\n",
        "\n",
        "        # Backpropagate and optimize\n",
        "        g_optimizer.zero_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # Print the loss every 50 batches\n",
        "        if (i+1) % 50 == 0:\n",
        "          print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}'\n",
        "                .format(epoch+1, num_epochs, i+1, len(train_dataloader), d_loss.item(), g_loss.item()))"
      ],
      "metadata": {
        "id": "HS_iA3yvr9nS",
        "outputId": "082d1959-b7b5-4dfa-f409-c52f2316a05c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 784])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-d71a39666a21>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Train the discriminator on real and fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0md_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0md_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7bc9efacd05f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Pass the input through the first fully connected layer with ReLU activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Pass the output through the second fully connected layer with sigmoid activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (50176x1 and 784x256)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQN2ILNBHhxe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}